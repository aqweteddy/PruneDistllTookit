diff --git a/bash/train_sft.bash b/bash/train_sft.bash
index bf36a6d..56d8b1f 100644
--- a/bash/train_sft.bash
+++ b/bash/train_sft.bash
@@ -11,9 +11,11 @@ accelerate launch --config_file deepspeed_cfg/zero2.yml --num_processes 4 train_
 --optim paged_adamw_8bit \
 --lr_scheduler_type cosine \
 --warmup_steps 100 \
+--max_seq_length 4096 \
 --per_device_train_batch_size 1 \
 --num_train_epochs 3 \
 --gradient_checkpointing \
 --report_to wandb \
+--bf16 \
 --save_only_model \
 --save_safetensors 
diff --git a/train_script/sft.py b/train_script/sft.py
index 0ff1734..639962a 100644
--- a/train_script/sft.py
+++ b/train_script/sft.py
@@ -27,7 +27,6 @@ if __name__ == "__main__":
         attn_implementation='flash_attention_2',
         torch_dtype=model_config.torch_dtype,
     )
-    training_args.model_init_kwargs = model_kwargs
     tokenizer = AutoTokenizer.from_pretrained(
         model_config.model_name_or_path, 
         trust_remote_code=model_config.trust_remote_code, 
